# -*- coding: utf-8 -*-
"""Edit_Telco_Customer_Churn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k6EExujcSQl1JHXOHLoVFpYUfKinEawk
"""

from google.colab import drive
drive.mount('/content/drive')

"""## **Idea 2: Customer Churn Prediction**
   ## **Data Train**

### **Business Understanding**

**About Dataset**:

Context
"Predict behavior to retain customers. You can analyze all relevant customer data and develop focused customer retention programs." [IBM Sample Data Sets]

Content
Each row represents a customer, each column contains customerâ€™s attributes described on the column Metadata.

The data set includes information about:

Customers who left within the last month â€“ the column is called Churn
Services that each customer has signed up for â€“ phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies
Customer account information â€“ how long theyâ€™ve been a customer, contract, payment method, paperless billing, monthly charges, and total charges
Demographic info about customers â€“ gender, age range, and if they have partners and dependents
Inspiration
To explore this type of models and learn more about the subject.

New version from IBM:
https://community.ibm.com/community/user/businessanalytics/blogs/steven-macko/2019/07/11/telco-customer-churn-1113

Data Sheet = WA_Fn-UseC_-Telco-Customer-Churn.csv \
https://www.kaggle.com/datasets/blastchar/telco-customer-churn/data?select=WA_Fn-UseC_-Telco-Customer-Churn.csv

7,043 rows Ã— 21 columns

977.5 KB
"""

#Import Library
import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import QuantileTransformer
from sklearn.metrics import confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import SelectFromModel
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score
#-------------------------------------------------------------------------------------------------------------------------------
pd.set_option('display.max_columns', None )
import warnings                                                     # Importing warning to disable runtime warnings
warnings.filterwarnings("ignore")

"""## Exploratory Data Analysis (EDA)"""

#Reading the dataset
df= pd.read_csv('/content/drive/MyDrive/2. Telco Customer Churn/WA_Fn-UseC_-Telco-Customer-Churn.csv')
df

df.columns

"""Feature Summary :


* customerID: The customer's unique identification number
* gender: The customer's gender (male or female)
* SeniorCitizen: Indicates whether the customer is a senior (0 or 1)
* Partner: Indicates whether the customer has a partner (Yes or No)
* Dependents: Indicates whether the customer has dependents (Yes or No)  
* Tenure: The customer's duration of stay with the company  
* PhoneService: Indicates whether the customer has phone service (Yes or No)
* MultipleLines: Indicates whether the customer has multiple lines (Yes or No or No phone service)
* InternetService: The customer's service provider (No, DSL, or Fiber Optic)
* OnlineSecurity: Indicates whether the customer has internet security (Yes, No or No internet service)
* OnlineBackup: Indicates whether the customer has online backup (Yes, No or No internet service)
* DeviceProtection: Indicates whether the customer has device protection (Yes, No or No internet service)
* TechSupport: Indciates whether the customer has tech support (Yes, No or No internet service)
* StreamingTV: Indicates whether the customer streams TV (Yes, No or No internet service)
* StreamingMovies: Indicates whether the customer streams movies (Yes, No, or No internet service)
* Contract: The customer's current contract term (Month-to-month, One year, Two year)
* PaperlessBilling: Indicates whether the customer has paperless billing (Yes or No)
* PaymentMethod: The customer's payment method (Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic))
* MonthlyCharges: The monthly amount charged to the customer
* TotalCharges: Total amount charged to the customer
* Churn: Indicates whether the customer has churn or not (Yes or No)

### Making labels concise
"""

## Shorten the Labels
value_mapper = {'Female': 'F', 'Male': 'M', 'Yes': 'Y', 'No': 'N',
                'No phone service': 'No phone', 'Fiber optic': 'FO',
                'No internet service': 'No internet', 'Month-to-month': 'Monthly',
                'Bank transfer (automatic)': 'Bank_transfer',
                'Credit card (automatic)': 'Credit_card',
                }
df.replace(to_replace=value_mapper, inplace=True)

#Check info
df.head()

"""### Let's also change column labels from TitleCase to lowercase to ease access."""

# to lowercase
df.columns = [label.lower() for label in df.columns]
df.head(10)

df.info()

"""totalcharges column is recognized as object instead of float.\
totalcharges column change to float
"""

#change to float
df['totalcharges'] = pd.to_numeric(df['totalcharges'], errors='coerce')
df['totalcharges'].head()

"""seniorcitizen column is recognized as int instead of object.\
seniorcitizen column change to object.
"""

#change to object
df['seniorcitizen'] = df['seniorcitizen'].astype(object)
df['seniorcitizen'].head()

"""Checking the distribution of data in missing value & outliers columns to decide whether to replace it with mean or median."""

#Count missing values (null)
df.isna().sum()

"""totalcharges missing value = 11"""

# Handle Missing Value and Ouliers
def handle_outliers(cols):
    sorted(cols)
    Q1, Q3 = np.percentile(cols, [25,75])
    IQR = Q3 - Q1
    lb = Q1 - (1.5*IQR)
    ub = Q3 + (1.5*IQR)
    return lb, ub

for cols in df.columns:
    if df[cols].dtype != 'object':
        lr,ur = handle_outliers(df[cols])
        df.loc[df[cols] > ur, cols] = np.nan
        df.loc[df[cols] < lr, cols] = np.nan

missing_cols = ['totalcharges']

for col in missing_cols:
    sns.displot(data=df, x=col, kind='kde')

# Filling missing values in the current column with the median or mean
for col in missing_cols:
    if col != 'totalcharges':
        df[col].fillna(df[col].median(), inplace=True)
    else:
        df[col].fillna(df[col].mean(), inplace=True)

#Count missing values (null)
df.isna().sum()

df.info()

df[np.isnan(df['totalcharges'])]

#Check duplicate
df.duplicated().sum()

# Count number of unique values
df.nunique()

# Result returns true so we drop column customerid
df = df.drop('customerid', axis = 1)
df

"""### Correlations in the data"""

df.describe().T

# Correlation between Quantitative variable (metode corelation Pearson)
sns.heatmap(data=df[['tenure', 'monthlycharges', 'totalcharges']].corr(),
            annot=True, cmap='coolwarm');

"""Inference: As evident from the correlation matrix and regplots, since 'totalcharges' is the total monthly charges over the tenure of a customer, 'totalcharges' is highly correlated with 'monthlycharges' and 'tenure'."""

# Plotting linear regression between 'monthlycharges' and 'totalcharges' while separating by 'churn' variable
sns.lmplot(x='monthlycharges', y='totalcharges', data=df, hue='churn', scatter_kws={'alpha': 0.1})

# Plotting linear regression between 'tenure' and 'totalcharges' while separating by 'churn' variable
sns.lmplot(x='tenure', y='totalcharges', data=df, hue='churn', scatter_kws={'alpha': 0.1})

"""Dropping TotalCharges \
We notice that both the columns tenure and MonthlyCharges are highly correlated with the column TotalCharges, which indicates that TotalCharges is the culprit. Instead of just dropping the featureTotalCharges altogether without much explaination, I think it's better if we at least provide a justification for it. \

Through some observation and domain knowledege, a customer's total accumulated charge must be at least related to the product of the customer's monthly charge and tenure. Indeed, if we plot the correlation matrix between TotalCharges and this product, which we will name EstimatedCharges, we see something interesting
"""

# Computing the elementwise product between tenure and monthlycharges
mult = df[["monthlycharges"]].multiply(df["tenure"], axis="index")
mult = mult.rename(columns={"monthlycharges" : "estimatedcharges"})
mat = pd.concat([mult, df['totalcharges']], axis = 1)
print(mat)

plt.figure(figsize = (20,7))
sns.set(style = 'whitegrid')

# Graphing the correlation matrix
plt.subplot(1,2,1)
sns.heatmap(mat.corr(), annot = True)

# Graphing a scatterplot of all entries
plt.subplot(1,2,2)
sns.scatterplot(data = mat, x = 'estimatedcharges', y = 'totalcharges')

"""We see that the correlation between features EstimatedCharges and TotalCharges are identically 1, which indicates that these two features are perfectly positively correlated. Indeed, the scatterplot for these two features agrees with our analysis.

Now, should we drop the two features MonthlyCharges and tenure which makes up our EstimatedCharges, or the feature TotalCharges?

Indeed on the basis of keeping the most information available, we should drop the columnTotalCharges since we can certainly (approximately) derive this column by multiplying MontlyCharge and tenure, but we cannot derive the other two columns using TotalCharges only.
"""

#Drop totalcharges
df = df.drop('totalcharges', axis = 1)

df.info()

"""This function is designed to annotate the bars in a bar plot with the percentage of each bar's"""

# Useful Helper Function
def annotate_percent(ax, df, total):
    for p in ax.patches:
        percentage = '{:.1f}%'.format(100 * p.get_height() / total)
        x = p.get_x() + p.get_width() / 2
        y = p.get_height() / 2
        ax.annotate(percentage, (x,y), ha = 'center', fontsize = 15,  weight = 'bold')

"""Churning Rates\
We want to investigate the number of customers who have and have not churned. This will inform our decision when it comes to analyzing other categorical variables in our data
"""

# Churning Rates
plt.figure(figsize = (8,8))
sns.set(style = 'whitegrid')
ax = sns.countplot(data = df, x = 'churn', palette='Set3')
annotate_percent(ax, df, df.shape[0])

"""Customer Demographics\
We would want to identify common themes between the columns gender, seniorcitizen, partner, and dependents since it relates to the customer's personal status.
"""

# Perform a Categorical Summary
plt.figure(figsize = (32,8))
sns.set(style = 'whitegrid')

plt.subplot(1,4,1)
ax1 = sns.countplot(data = df, x = 'gender', palette='Set2')
annotate_percent(ax1, df, df.shape[0])

plt.subplot(1,4,2)
ax2 = sns.countplot(data = df, x = 'seniorcitizen', palette='Set2')
annotate_percent(ax2, df, df.shape[0])

plt.subplot(1,4,3)
ax3 = sns.countplot(data = df, x = 'partner', palette='Set2')
annotate_percent(ax3, df, df.shape[0])

plt.subplot(1,4,4)
ax4 = sns.countplot(data = df, x = 'dependents', palette='Set2')
annotate_percent(ax4, df, df.shape[0])

"""We would like to explore the correlation between dependents given partner, and seniorcitizen"""

# Graph the number of dependents conditioned on partners
fig, axes = plt.subplots(1,2, figsize = (16,8))

# Group Counts
count_partner = df.groupby(['partner', 'dependents']).size().unstack(fill_value = 0)
count_senior = df.groupby(['seniorcitizen', 'dependents']).size().unstack(fill_value = 0)

# Plot
count_partner.plot(kind = 'bar', stacked = True, ax = axes[0])
count_senior.plot(kind = 'bar', stacked = True, ax = axes[1])

"""Phone & Internet Services\
We would want to graph the number of customers who have phone and internet services (the column PhoneService and InternetService)
"""

# Plots of phone services
plt.figure(figsize = (16,8))
sns.set(style = 'whitegrid')

phone_cols = ['phoneservice', 'multiplelines']
df_phone = df[phone_cols]
cnt = 0

for lbl in phone_cols:
    plt.subplot(1,2,cnt + 1)
    ax = sns.countplot(data = df, x = lbl, palette='Set1')
    annotate_percent(ax, df_phone, df_phone.shape[0])
    cnt += 1

"""An observation shows that the percentage of customers who have phone service is the same as \
the number of people who don't have multiple lines.
"""

# Plots of internet services

plt.figure(figsize = (32,16))
sns.set(style = 'whitegrid')

axes = []
inter_cols = ['internetservice', 'onlinesecurity', 'onlinebackup',
              'deviceprotection', 'techsupport', 'streamingtv', 'streamingmovies']
df_internet = df[inter_cols]
cnt = 0

for lbl in inter_cols:
    plt.subplot(2,4, cnt + 1)
    ax = sns.countplot(data = df, x = lbl, palette='Set2')
    axes.append(ax)
    annotate_percent(axes[cnt], df_internet, df_internet.shape[0])
    cnt += 1

"""Percentage of customers with no internet service is the same for all seven plot. This is worth investigating over."""

df_phone[df['phoneservice'] == 'N']

df_internet[df['internetservice'] == 'N']

# Verify our assumption for phone service
mask = ((df_phone['phoneservice'] == 'N') & (df_phone['multiplelines'] == 'No phone'))
comp = (df_phone.loc[mask] == df_phone[df['phoneservice'] == 'N'])
comp.value_counts()

# For internet service
mask = df_internet['internetservice'] == 'N'
for lbl in inter_cols:
    if lbl != 'internetservice':
        mask = mask & (df_internet[lbl] == 'No internet')

comp = (df_internet[df_internet['internetservice'] == 'N']) == df_internet.loc[mask]
comp.value_counts()

"""As we have compared every entry in the dataframe with our condition, we can verify that indeed, if a customer has no internet service (resp. no phone service), then they cannot sign up to any additional features that requires internet service (resp. phone service) to use.

Financial Status\
Lastly, we would like to explore the number of customers with respect to contract types (column Contract), and methods of payment (columns PaperlessBilling and PaymentMethod)
"""

# Plot relevant figures

plt.figure(figsize = (24, 8))
sns.set(style = 'whitegrid')

plt.subplot(1,3,1)
ax1 = sns.countplot(data = df, x = 'contract', palette='Set3')
annotate_percent(ax1, df, df.shape[0])

plt.subplot(1,3,2)
ax2 = sns.countplot(data = df, x = 'paperlessbilling', palette='Set3')
annotate_percent(ax2, df, df.shape[0])

plt.subplot(1,3,3)
ax3 = sns.countplot(data = df, x = 'paymentmethod', palette='Set3')
annotate_percent(ax3, df, df.shape[0])

"""Tenure and Types of Contract\
It is worth it to explore the types of contract in correlation to the customer's tenure in months, along with churning rates.
"""

plt.figure(figsize = (24,8))
sns.set(style = 'whitegrid')

plt.subplot(1,3,1)
ax1 = sns.histplot(data = df[df['contract'] == 'Monthly'], x = 'tenure', hue = 'churn', palette='Set2', bins = 30, kde = True)
ax1.set_title('Tenure of customers with month-to-month contracts')

plt.subplot(1,3,2)
ax2 = sns.histplot(data = df[df['contract'] == 'One year'], x = 'tenure', hue = 'churn', palette='Set2', bins = 30, kde = True)
ax2.set_title('Tenure of customers with one-year contracts')

plt.subplot(1,3,3)
ax3 = sns.histplot(data = df[df['contract'] == 'Two year'],  x = 'tenure', hue =  'churn', palette='Set2', bins = 30, kde = True)
ax3.set_title('Tenure of customers with two-year contracts')

"""Explaination\
We can see that the majority of customers with one-month-contract and short tenure are the most likely culprit for churning. The number of churning customers are especially high at the first three months since customers are not too invested in the telecom plans.

Payment Method\
For the payment method, we will analyze the number of customers that are registed for automatic payment (Bank transfer, Credit Card) or manual deposits (Electronic or Mailed Check) in relation to churning rates.
"""

# Payment Method
dt = {'Bank_transfer' : 'auto',
      'Credit_card' : 'auto',
      'Electronic check' : 'manual',
      'Mailed check' : 'manual'}
def map_payment(elem):
    return dt[elem]

payment = df['paymentmethod'].map(map_payment)
payment = pd.concat([payment, df['churn']], axis = 1)

# Plot the count of people
plt.figure(figsize = (16,8))
sns.set(style = 'whitegrid')

plt.subplot(1,2,1)
ax1 = sns.countplot(data = payment.loc[payment['paymentmethod'] == 'auto'], x = 'churn', palette='Set2')
annotate_percent(ax1, payment, payment.shape[0])
ax1.set_title('Payment method auto')

plt.subplot(1,2,2)
ax2 = sns.countplot(data = payment.loc[payment['paymentmethod'] == 'manual'], x = 'churn', palette='Set2')
annotate_percent(ax2, payment, payment.shape[0])
ax2.set_title('Payment method manual')

"""We can see that the number of people whose payment method are manual are 2.5 times more likely to churn compared to people who set their payment method to automatic."""

df.isna().sum()

"""## **Data Preprocessing**

**Boolean Feature Conversion**\
From our variable summary and type inference, we can see that some features in the dataset are of undesirable type. The list of which is as follows:

partner: object â†’ boolean\
dependents: object â†’ boolean\
phoneservice: object â†’ boolean\
paperlessbilling: object â†’ boolean\
totalcharges: object â†’ float64
churn: object â†’ boolean\
We proceed to convert these columns into our required type, as well as mapping features with yes/no to corresponding boolean outputs (1 and 0)
"""

# Boolean Conversion (yes/no to 1/0)
bool_map = {'N' : 0, 'Y' : 1}
bool_cols = ['partner', 'dependents', 'phoneservice', 'paperlessbilling', 'churn']

for lb in bool_cols:
    df[lb] = df[lb].map(bool_map)

# Verify that all boolean conversions are correct
for x in bool_cols:
    print(f"Feature '{x}' has unique values: {df[x].unique()}")
print(df[bool_cols].dtypes)

"""**"Partially" Boolean Features**\
An observation in our dataset reveals that a number of features in our dataset is conditionally related to each other. Specifically:

If the value of the column phoneservice is No, then the value of multiplelines is guaranteed to be "No phone"\
If the value of the column internetservice is No, then the value of the columns onlinesecurity, onlinebackup, deviceprotection, techsupport, streamingtv, and streamingmovies is guranteed to be "No internet".
"""

# Convert SeniorCitizen back to boolean
df['seniorcitizen'] = df['seniorcitizen'].astype(int)
# Boolean Conversion (yes/no or no internet/phone service to 1/0)
bool_map_extended = {'N' : 0, 'Y' : 1, 'No internet' : 0, 'No phone' : 0}
partial_bools = ['multiplelines','onlinesecurity', 'onlinebackup', 'deviceprotection',
                 'techsupport', 'streamingtv', 'streamingmovies']

for lb in partial_bools:
    df[lb] = df[lb].map(bool_map_extended)
partial_bools.append('seniorcitizen')

# Verify that all boolean conversions are correct
for x in partial_bools:
    print(f"Feature '{x}' has unique values: {df[x].unique()}")
print(df[partial_bools].dtypes)

df.info()

"""**Label Encoding**\
We can see that the column InternetService is an ordinal categorical feature since we can impose an order on our \
internet service as No < DSL < Fiber optic.

The most suitable method for encoding this column is to use label encoding to suitably label these instances whilst preserving its order.
"""

# Label encode data
print(df['internetservice'].value_counts())
label_encode = {'N' : 0, 'DSL' : 1, 'FO' : 2}
df['internetservice'] = df['internetservice'].map(label_encode)
print(df['internetservice'].value_counts())

"""# **One Hot Encoding**
We see that the rest of our categorical features, Contract and PaymentMethod, are nominal categorical with more than 2 features. Since the number of features in these columns are relatively small, we can employ One Hot Encoding on these columns to retain maximum information.

In addition, since the categories in these columns are "linearly dependent" (e.g. a contract term that is not month-to-month and one-year is two-year), we can drop the first category to ensure linearly independent columns.
"""

# One Hot Encoding
onehot_gender = pd.get_dummies(df['gender'], drop_first = True, dtype = int)
onehot_contract = pd.get_dummies(df['contract'], drop_first = True, dtype = int)
onehot_payment = pd.get_dummies(df['paymentmethod'], drop_first = True, dtype = int)
df = pd.concat([df, onehot_gender, onehot_contract, onehot_payment], axis = 1)

# Drop original columns
df = df.drop(['gender', 'contract', 'paymentmethod'], axis = 1)
df

# Menyimpan DataFrame ke dalam file CSV
df.to_csv('data_setelah_encoding.csv', index=False)

"""**Column M:**\
**0 = Female**\
**1 = Male**

**Splitting The Dataset**\
We want to first split the data into three different parts :

Training data: which is used to train the model\
Cross-Validation data: which is used later for retraining / hyperparameter tuning\
Test data: which is used to blind-test the model to measure true accuracy

We will split with stratify for the training data and the -validation data, while performing a random split on the test data to mimic the process of collecting new data.
"""

# Split data
X = df.drop('churn', axis=1)
y = df['churn']

X_rest, X_test, y_rest, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train, X_cv, y_train, y_cv = train_test_split(X_rest, y_rest, test_size=0.2, random_state=42, stratify=y_rest)

# Print shape of training, test, and cross-validation data
print(f"Training Data Shape: {X_train.shape}")
print(f"Training Target Shape: {y_train.shape}")
print(f"Cross-Validation Data Shape: {X_cv.shape}")
print(f"Cross-Validation Target Shape: {y_cv.shape}")
print(f"Test Data Shape: {X_test.shape}")
print(f"Test Target Shape: {y_test.shape}")

"""Handling the imbalanced nature of dataset using SMOTE resampling technique"""

print('Before OverSampling, the shape of X: {}'.format(X.shape))
print('Before OverSampling, the shape of y: {} \n'.format(y.shape))

print("Before OverSampling, counts of label '1': {}".format(sum(y == 1)))
print("Before OverSampling, counts of label '0': {}".format(sum(y == 0)))

"""## **SMOTE** (Synthetic Minority Over-sampling Technique)"""

# Resampling using SMOTE (Synthetic Minority Over-sampling Technique)
sm = SMOTE(random_state=33)
X_res, y_res = sm.fit_resample(X, y.ravel())

print('After OverSampling, the shape of X: {}'.format(X_res.shape))
print('After OverSampling, the shape of y: {} \n'.format(y_res.shape))

print("After OverSampling, counts of label '1': {}".format(sum(y_res == 1)))
print("After OverSampling, counts of label '0': {}".format(sum(y_res == 0)))

X_res = pd.DataFrame(X_res)
y_res = pd.DataFrame(y_res)
y_res.columns = ['churn']

balanced_df = pd.concat([X_res, y_res], axis = 1)

X = balanced_df.drop(['churn'], axis=1)
y = balanced_df['churn']

"""Determining the best model by their success probability using CrossValidation

**LogisticRegression** vs **DecisionTreeClassifier** vs **RandomForestClassifier**
"""

# LogisticRegression
model_lr = LogisticRegression(max_iter=2000)
score_lr = round(cross_val_score(model_lr, X, y, cv=10, scoring='accuracy').mean(), 2) * 100
print("The mean accuracy score of LogisticRegression is {}%".format(score_lr))

# DecisionTreeClassifier
model_dt = DecisionTreeClassifier()
score_dt = round(cross_val_score(model_dt, X, y, cv=10, scoring='accuracy').mean(), 2) * 100
print("The mean accuracy score of DecisionTreeClassifier is {}%".format(score_dt))

# RandomForestClassifier
model_rf = RandomForestClassifier()
score_rf = round(cross_val_score(model_rf, X, y, cv=10, scoring='accuracy').mean(), 2) * 100
print("The mean accuracy score of RandomForestClassifier is {}%".format(score_rf))

"""## **1. LogisticRegression**

Applying **LogisticRegression with GridSearchCV** for parameter tuning
"""

# LogisticRegression with GridSearchCV for parameter tuning
model_lr = LogisticRegression()
param_grid = [{'penalty':['l1', 'l2', 'elasticnet', 'none'],
              'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}]
grid_search = GridSearchCV(model_lr, param_grid=param_grid, cv=10)
grid_search = grid_search.fit(X, y)
grid_search.best_params_

# Splitting data for Logistic Regression
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state = 42, stratify=y)

# Logistic Regression model with best parameters
model_lr = LogisticRegression(penalty='l2', solver='newton-cg', max_iter=2000)

# Train the model on the training data
model_lr.fit(X_train, y_train)

# Predicting labels for training and testing data using logistic regression model
y_train_pred = model_lr.predict(X_train)
y_test_pred = model_lr.predict(X_test)

# Calculating the accuracy of the model on training and testing data
train_acc = model_lr.score(X_train, y_train)
test_acc = model_lr.score(X_test, y_test)

print("Training accuracy is: ", train_acc*100)
print("Testing accuracy is :", test_acc*100)

"""Evaluating Train and Test datasets using **Confusion Matrix and Classification Report**"""

# Generating confusion matrix using predicted labels for training data
cm = confusion_matrix(y_train, y_train_pred)
cm
sns.set(font_scale = 1.2)
sns.heatmap(cm, annot=True, fmt='d', cmap='YlGnBu')

print(classification_report(y_train, y_train_pred))

# Generating confusion matrix using predicted labels for testing data
cm = confusion_matrix(y_test, y_test_pred)
cm
sns.set(font_scale = 1.2)
sns.heatmap(cm, annot=True, fmt='d', cmap="YlGnBu")

print(classification_report(y_test, y_test_pred))

import pickle

with open('logistic.pkl', 'wb') as pickle_out:
    pickle.dump(model_lr, pickle_out)

import joblib

# Simpan model dalam format joblib
joblib.dump(model_lr, 'logistic.joblib')

"""## **2. DecisionTreeClassifier**

Applying **DecisionTreeClassifier with GridSearchCV** for parameter tuning
"""

# DecisionTreeClassifier with GridSearchCV for parameter tuning
model_dt = DecisionTreeClassifier()
param_grid_dt = {'criterion': ['gini', 'entropy'],
                 'max_depth': [None, 10, 20, 30, 40, 50],
                 'min_samples_split': [2, 5, 10],
                 'min_samples_leaf': [1, 2, 4]}
grid_search_dt = GridSearchCV(model_dt, param_grid=param_grid_dt, cv=10)
grid_search_dt.fit(X, y)

grid_search_dt.best_params_

# Splitting data for DecisionTreeClassifier
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state = 42, stratify=y)

# DecisionTreeClassifier model with best parameters
model_dt = DecisionTreeClassifier(criterion='entropy', max_depth=10, min_samples_leaf=2, min_samples_split=5)

# Train the model on the training data
model_dt.fit(X_train, y_train)

# Predicting labels for training and testing data using DecisionTreeClassifier model
y_train_pred = model_dt.predict(X_train)
y_test_pred = model_dt.predict(X_test)

# Calculating the accuracy of the model on training and testing data
train_acc = model_dt.score(X_train, y_train)
test_acc = model_dt.score(X_test, y_test)

print("Training accuracy is: ", train_acc*100)
print("Testing accuracy is :", test_acc*100)

"""Evaluating Train and Test datasets using **Confusion Matrix and Classification Report**"""

# Generating confusion matrix using predicted labels for training data
cm = confusion_matrix(y_train, y_train_pred)
cm
sns.set(font_scale = 1.2)
sns.heatmap(cm, annot=True, fmt='d', cmap='YlGnBu')

print(classification_report(y_train, y_train_pred))

# Generating confusion matrix using predicted labels for testing data
cm = confusion_matrix(y_test, y_test_pred)
cm
sns.set(font_scale = 1.2)
sns.heatmap(cm, annot=True, fmt='d', cmap="YlGnBu")

print(classification_report(y_test, y_test_pred))

import pickle

with open('dtree.pkl', 'wb') as pickle_out:
    pickle.dump(model_dt, pickle_out)

import joblib

# Simpan model dalam format joblib
joblib.dump(model_dt, 'dtree.joblib')

"""## **3. RandomForestClassifier**

Applying **RandomForestClassifier with GridSearchCV** for parameter tuning
"""

# RandomForestClassifier with GridSearchCV for parameter tuning
model_rf = RandomForestClassifier()
param_grid_rf = {'n_estimators': [50, 100, 200],
                 'max_depth': [10, 20, 30, None],
                 'min_samples_split': [2, 5, 10],
                 'min_samples_leaf': [1, 2, 4],
                 'bootstrap': [True, False]}
grid_search_rf = GridSearchCV(model_rf, param_grid=param_grid_rf, cv=10)
grid_search_rf.fit(X, y)

grid_search_rf.best_params_

# Splitting data for RandomForestClassifier
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state = 42, stratify=y)

# RandomForestClassifier model with best parameters
model_rf = RandomForestClassifier(n_estimators= 100, max_depth=30, min_samples_leaf=1, min_samples_split=5, bootstrap=False)

# Train the model on the training data
model_rf.fit(X_train, y_train)

# Predicting labels for training and testing data using RandomForestClassifier model
y_train_pred = model_rf.predict(X_train)
y_test_pred = model_rf.predict(X_test)

# Calculating the accuracy of the model on training and testing data
train_acc = model_rf.score(X_train, y_train)
test_acc = model_rf.score(X_test, y_test)

print("Training accuracy is: ", train_acc*100)
print("Testing accuracy is :", test_acc*100)

"""Evaluating Train and Test datasets using **Confusion Matrix and Classification Report**"""

# Generating confusion matrix using predicted labels for training data
cm = confusion_matrix(y_train, y_train_pred)
cm
sns.set(font_scale = 1.2)
sns.heatmap(cm, annot=True, fmt='d', cmap='YlGnBu')

print(classification_report(y_train, y_train_pred))

# Generating confusion matrix using predicted labels for testing data
cm = confusion_matrix(y_test, y_test_pred)
cm
sns.set(font_scale = 1.2)
sns.heatmap(cm, annot=True, fmt='d', cmap="YlGnBu")

print(classification_report(y_test, y_test_pred))

import pickle

with open('rforest.pkl', 'wb') as pickle_out:
    pickle.dump(model_rf, pickle_out)

import joblib

# Simpan model dalam format joblib
joblib.dump(model_rf, 'rforest.joblib')

"""## **Conclusion:**

**RandomForestClassifier achieved the highest accuracy of 85.0%**, making it an effective choice for Telco Customer Churn. Meanwhile, the LogisticRegression achieved an accuracy of 82.0%, showing promise as well. Both models demonstrate strong potential in detecting Telco Customer Churn. DecisionTreeClassifier achieved an accuracy of 80.0% Considerations such as model complexity and computational resources should be taken into account when selecting the most suitable algorithm for fraud detection applications.
"""



"""**The below code (app.py) contains unpickling , Prediction and the inputs to our churn predictor model**

###**1. logistic (LogisticRegression)**
"""

# Commented out IPython magic to ensure Python compatibility.
# # LogisticRegression
# # file streamlit = app1.py
# # file model = logistic.joblib
# 
# %%writefile app1.py
# 
# import joblib
# import streamlit as st
# 
# model_file = 'logistic.joblib'
# 
# pickle_in = open(model_file, 'rb')   # Unpickling
# classifier = joblib.load(pickle_in)
# 
# st.set_page_config(page_title='ChurnPredictor', page_icon="ðŸ––")    # The set_page_config method lets us define the webpage title name and icon
# 
# @st.cache_data()
# # Define the function which will make the prediction using data inputs from users
# def prediction(seniorcitizen, partner, dependents, tenure, phoneservice, multiplelines,
#                internetservice, onlinesecurity, onlinebackup, deviceprotection, techsupport,
#                streamingtv, streamingmovies, paperlessbilling, monthlycharges, M,
#                one_year, two_year, credit_card, electronic_check, mailed_check):
# 
#     # Make predictions
#     prediction = classifier.predict(
#         [[seniorcitizen, partner, dependents, tenure, phoneservice, multiplelines,
#           internetservice, onlinesecurity, onlinebackup, deviceprotection, techsupport,
#           streamingtv, streamingmovies, paperlessbilling, monthlycharges, M,
#           one_year, two_year, credit_card, electronic_check, mailed_check]])
# 
#     if prediction == 0:
#         pred = 'Everything Looks good. The Customer is Loyal!'
#     else:
#         pred = 'Oh No! The customer is gonna CHURN! **Better do something about it**'
#     return pred
# 
# # This is the main function in which we define our webpage
# def main():
# 
#     st.title("The Churn Predictor Model")   # Title of the model displayed in the webpage
# 
#     # Give a little bit information of the Model
#     st.info('The Model takes in the below predictor variables for a telecom company and predicts if a customer is going to churn or not!', icon="â„¹ï¸")
# 
#     # Create input fields
#     seniorcitizen = st.number_input("Are you a senior citizen ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     partner = st.number_input("Do you have a partner ? ('1' for Yes and '0' for NO) ", min_value=0, max_value=1, value=0, step=1)
#     dependents = st.number_input("Do you have any dependents ? ('1' for Yes and '0' for NO) ", min_value=0, max_value=1, value=0, step=1)
#     tenure = st.number_input("Enter the months the customer (tenure) has stayed with the company(0-72)", min_value=0, max_value=72, value=10, step=3)
#     phoneservice = st.number_input("Did the customer have a phone service ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     multiplelines = st.number_input("Did the customer have a multiplelines ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     internetservice = st.number_input("Did the customer have a internetservices ? ('N' : 0, 'DSL' : 1, 'FO (Fiber Optic)' : 2)", min_value=0, max_value=2, value=0, step=1)
#     onlinesecurity = st.number_input("Did the customer have a onlinesecuritys ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     onlinebackup = st.number_input("Did the customer have a onlinebackup ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     deviceprotection = st.number_input("Did the customer have a deviceprotection ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     techsupport = st.number_input("Did the customer have a techsupport ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     streamingtv = st.number_input("Did the customer have a streamingtv ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     streamingmovies = st.number_input("Did the customer have a streamingmovies ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     paperlessbilling = st.number_input("Did the customer use paperless billing? ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     monthlycharges = st.number_input("Enter the monthlycharges the customer (0-118.75)", min_value=0.0, max_value=118.75, value=10.0, step=3.0)
#     M = st.number_input("Are you a Male or Female ? ('1' for Male and '0' for Female)", min_value=0, max_value=1, value=0, step=1)
#     one_year = st.number_input("Does the customer have One year contract ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     two_year = st.number_input("Does the customer have Two year contract ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     credit_card = st.number_input("Did the customer use Credit_card? ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     electronic_check = st.number_input("Did the customer use Electronic check ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     mailed_check = st.number_input("Did the customer use Mailed check ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
# 
# 
#     result = ""
# 
#     # When 'Predict' is clicked, make the prediction and store it
#     if st.button("Predict"):
#         result = prediction(seniorcitizen, partner, dependents, tenure, phoneservice, multiplelines,
#                             internetservice, onlinesecurity, onlinebackup, deviceprotection, techsupport,
#                             streamingtv, streamingmovies, paperlessbilling, monthlycharges, M,
#                             one_year, two_year, credit_card, electronic_check, mailed_check)
#         st.success(result)
#         # If the predictions are true, celebrate that the model is properly working, else spit out a churn warning
#         if result == 'Everything Looks good. The Customer is Loyal!':
#             st.balloons()
#         else:
#             st.image('https://www.smartkarrot.com/wp-content/uploads/2020/09/Customer-churn-reduction.png',
#                      caption="Customer CHURN ALERT", width=150)
# 
# if __name__ == '__main__':
#     main()
#



"""###**2. dtree (DecissionTree)**"""

# Commented out IPython magic to ensure Python compatibility.
# # DecissionTree
# # file streamlit = app2.py
# # file model = dtree.joblib
# 
# %%writefile app2.py
# 
# import joblib
# import streamlit as st
# 
# model_file = 'dtree.joblib'
# 
# # Memuat model dengan joblib.load
# classifier = joblib.load(model_file)
# 
# st.set_page_config(page_title='ChurnPredictor', page_icon="ðŸ––")    # The set_page_config method lets us define the webpage title name and icon
# 
# @st.cache_data()
# # Define the function which will make the prediction using data inputs from users
# def prediction(seniorcitizen, partner, dependents, tenure, phoneservice, multiplelines,
#                internetservice, onlinesecurity, onlinebackup, deviceprotection, techsupport,
#                streamingtv, streamingmovies, paperlessbilling, monthlycharges, M,
#                one_year, two_year, credit_card, electronic_check, mailed_check):
# 
#     # Make predictions
#     prediction = classifier.predict(
#         [[seniorcitizen, partner, dependents, tenure, phoneservice, multiplelines,
#           internetservice, onlinesecurity, onlinebackup, deviceprotection, techsupport,
#           streamingtv, streamingmovies, paperlessbilling, monthlycharges, M,
#           one_year, two_year, credit_card, electronic_check, mailed_check]])
# 
#     if prediction == 0:
#         pred = 'Everything Looks good. The Customer is Loyal!'
#     else:
#         pred = 'Oh No! The customer is gonna CHURN! **Better do something about it**'
#     return pred
# 
# # This is the main function in which we define our webpage
# def main():
# 
#     st.title("The Churn Predictor Model")   # Title of the model displayed in the webpage
# 
#     # Give a little bit information of the Model
#     st.info('The Model takes in the below predictor variables for a telecom company and predicts if a customer is going to churn or not!', icon="â„¹ï¸")
# 
#     # Create input fields
#     seniorcitizen = st.number_input("Are you a senior citizen ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     partner = st.number_input("Do you have a partner ? ('1' for Yes and '0' for NO) ", min_value=0, max_value=1, value=0, step=1)
#     dependents = st.number_input("Do you have any dependents ? ('1' for Yes and '0' for NO) ", min_value=0, max_value=1, value=0, step=1)
#     tenure = st.number_input("Enter the months the customer (tenure) has stayed with the company(0-72)", min_value=0, max_value=72, value=10, step=3)
#     phoneservice = st.number_input("Did the customer have a phone service ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     multiplelines = st.number_input("Did the customer have a multiplelines ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     internetservice = st.number_input("Did the customer have a internetservices ? ('N' : 0, 'DSL' : 1, 'FO (Fiber Optic)' : 2)", min_value=0, max_value=2, value=0, step=1)
#     onlinesecurity = st.number_input("Did the customer have a onlinesecuritys ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     onlinebackup = st.number_input("Did the customer have a onlinebackup ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     deviceprotection = st.number_input("Did the customer have a deviceprotection ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     techsupport = st.number_input("Did the customer have a techsupport ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     streamingtv = st.number_input("Did the customer have a streamingtv ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     streamingmovies = st.number_input("Did the customer have a streamingmovies ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     paperlessbilling = st.number_input("Did the customer use paperless billing? ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     monthlycharges = st.number_input("Enter the monthlycharges the customer (0-118.75)", min_value=0.0, max_value=118.75, value=10.0, step=3.0)
#     M = st.number_input("Are you a Male or Female ? ('1' for Male and '0' for Female)", min_value=0, max_value=1, value=0, step=1)
#     one_year = st.number_input("Does the customer have One year contract ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     two_year = st.number_input("Does the customer have Two year contract ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     credit_card = st.number_input("Did the customer use Credit_card? ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     electronic_check = st.number_input("Did the customer use Electronic check ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     mailed_check = st.number_input("Did the customer use Mailed check ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
# 
# 
#     result = ""
# 
#     # When 'Predict' is clicked, make the prediction and store it
#     if st.button("Predict"):
#         result = prediction(seniorcitizen, partner, dependents, tenure, phoneservice, multiplelines,
#                             internetservice, onlinesecurity, onlinebackup, deviceprotection, techsupport,
#                             streamingtv, streamingmovies, paperlessbilling, monthlycharges, M,
#                             one_year, two_year, credit_card, electronic_check, mailed_check)
#         st.success(result)
#         # If the predictions are true, celebrate that the model is properly working, else spit out a churn warning
#         if result == 'Everything Looks good. The Customer is Loyal!':
#             st.balloons()
#         else:
#             st.image('https://www.smartkarrot.com/wp-content/uploads/2020/09/Customer-churn-reduction.png',
#                      caption="Customer CHURN ALERT", width=150)
# 
# if __name__ == '__main__':
#     main()
#

"""###**3. rforest (RandomForestClassifier)**"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app3.py
# 
# import joblib
# import streamlit as st
# 
# model_file = 'rforest.joblib'
# 
# pickle_in = open(model_file, 'rb')   # Unpickling
# classifier = joblib.load(pickle_in)
# 
# st.set_page_config(page_title='ChurnPredictor', page_icon="ðŸ––")    # The set_page_config method lets us define the webpage title name and icon
# 
# @st.cache_data()
# # Define the function which will make the prediction using data inputs from users
# def prediction(seniorcitizen, partner, dependents, tenure, phoneservice, multiplelines,
#                internetservice, onlinesecurity, onlinebackup, deviceprotection, techsupport,
#                streamingtv, streamingmovies, paperlessbilling, monthlycharges, M,
#                one_year, two_year, credit_card, electronic_check, mailed_check):
# 
#     # Make predictions
#     prediction = classifier.predict(
#         [[seniorcitizen, partner, dependents, tenure, phoneservice, multiplelines,
#           internetservice, onlinesecurity, onlinebackup, deviceprotection, techsupport,
#           streamingtv, streamingmovies, paperlessbilling, monthlycharges, M,
#           one_year, two_year, credit_card, electronic_check, mailed_check]])
# 
#     if prediction == 0:
#         pred = 'Everything Looks good. The Customer is Loyal!'
#     else:
#         pred = 'Oh No! The customer is gonna CHURN! **Better do something about it**'
#     return pred
# 
# # This is the main function in which we define our webpage
# def main():
# 
#     st.title("The Churn Predictor Model")   # Title of the model displayed in the webpage
# 
#     # Give a little bit information of the Model
#     st.info('The Model takes in the below predictor variables for a telecom company and predicts if a customer is going to churn or not!', icon="â„¹ï¸")
# 
#     # Create input fields
#     seniorcitizen = st.number_input("Are you a senior citizen ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     partner = st.number_input("Do you have a partner ? ('1' for Yes and '0' for NO) ", min_value=0, max_value=1, value=0, step=1)
#     dependents = st.number_input("Do you have any dependents ? ('1' for Yes and '0' for NO) ", min_value=0, max_value=1, value=0, step=1)
#     tenure = st.number_input("Enter the months the customer (tenure) has stayed with the company(0-72)", min_value=0, max_value=72, value=10, step=3)
#     phoneservice = st.number_input("Did the customer have a phone service ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     multiplelines = st.number_input("Did the customer have a multiplelines ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     internetservice = st.number_input("Did the customer have a internetservices ? ('N' : 0, 'DSL' : 1, 'FO (Fiber Optic)' : 2)", min_value=0, max_value=2, value=0, step=1)
#     onlinesecurity = st.number_input("Did the customer have a onlinesecuritys ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     onlinebackup = st.number_input("Did the customer have a onlinebackup ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     deviceprotection = st.number_input("Did the customer have a deviceprotection ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     techsupport = st.number_input("Did the customer have a techsupport ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     streamingtv = st.number_input("Did the customer have a streamingtv ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     streamingmovies = st.number_input("Did the customer have a streamingmovies ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     paperlessbilling = st.number_input("Did the customer use paperless billing? ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     monthlycharges = st.number_input("Enter the monthlycharges the customer (0-118.75)", min_value=0.0, max_value=118.75, value=10.0, step=3.0)
#     M = st.number_input("Are you a Male or Female ? ('1' for Male and '0' for Female)", min_value=0, max_value=1, value=0, step=1)
#     one_year = st.number_input("Does the customer have One year contract ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     two_year = st.number_input("Does the customer have Two year contract ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     credit_card = st.number_input("Did the customer use Credit_card? ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     electronic_check = st.number_input("Did the customer use Electronic check ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
#     mailed_check = st.number_input("Did the customer use Mailed check ? ('1' for Yes and '0' for NO)", min_value=0, max_value=1, value=0, step=1)
# 
# 
#     result = ""
# 
#     # When 'Predict' is clicked, make the prediction and store it
#     if st.button("Predict"):
#         result = prediction(seniorcitizen, partner, dependents, tenure, phoneservice, multiplelines,
#                             internetservice, onlinesecurity, onlinebackup, deviceprotection, techsupport,
#                             streamingtv, streamingmovies, paperlessbilling, monthlycharges, M,
#                             one_year, two_year, credit_card, electronic_check, mailed_check)
#         st.success(result)
#         # If the predictions are true, celebrate that the model is properly working, else spit out a churn warning
#         if result == 'Everything Looks good. The Customer is Loyal!':
#             st.balloons()
#         else:
#             st.image('https://www.smartkarrot.com/wp-content/uploads/2020/09/Customer-churn-reduction.png',
#                      caption="Customer CHURN ALERT", width=150)
# 
# if __name__ == '__main__':
#     main()
#

pip list